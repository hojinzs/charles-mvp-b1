# Charles Monitor MVP - ëª¨ë‹ˆí„°ë§ ì œì•ˆì„œ

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ì£¼ ëª©í‘œ

### 1. ì„œë¹„ìŠ¤ ì•ˆì •ì„± ë³´ì¥
- í¬ë¡¤ë§ ì„œë¹„ìŠ¤ì˜ ì§€ì†ì ì¸ ê°€ìš©ì„± í™•ë³´
- ì¥ì•  ë°œìƒ ì‹œ ì‹ ì†í•œ ê°ì§€ ë° ëŒ€ì‘
- ì‚¬ìš©ì ê²½í—˜ ì €í•˜ ì‚¬ì „ ë°©ì§€

### 2. ì„±ëŠ¥ ìµœì í™”
- í¬ë¡¤ë§ ì‘ì—…ì˜ ì²˜ë¦¬ ì‹œê°„ ë° ì²˜ë¦¬ëŸ‰ ì¶”ì 
- ë³‘ëª© êµ¬ê°„ ì‹ë³„ ë° ê°œì„ 
- ë¦¬ì†ŒìŠ¤ ì‚¬ìš© ìµœì í™”

### 3. ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ í™•ë³´
- í¬ë¡¤ë§ ì„±ê³µë¥  ë° ì‹¤íŒ¨ ì›ì¸ ë¶„ì„
- ì‚¬ìš©ì í™œë™ íŒ¨í„´ íŒŒì•…
- ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬

---

## ğŸ¯ ëª¨ë‹ˆí„°ë§í•  ì£¼ìš” ì§€í‘œ

### A. ì¸í”„ë¼ ì§€í‘œ (Infrastructure Metrics)

#### 1. ì• í”Œë¦¬ì¼€ì´ì…˜ Health
| ì§€í‘œ | ì„¤ëª… | ì„ê³„ê°’ |
|------|------|--------|
| `app_uptime` | ì„œë¹„ìŠ¤ ê°€ë™ ì‹œê°„ | - |
| `app_restart_count` | ì¬ì‹œì‘ íšŸìˆ˜ | 5íšŒ/ì‹œê°„ ì´ˆê³¼ ì‹œ ì•Œë¦¼ |
| `memory_usage` | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB) | 70% ì´ˆê³¼ ì‹œ ê²½ê³  |
| `cpu_usage` | CPU ì‚¬ìš©ë¥  (%) | 80% ì´ˆê³¼ ì‹œ ê²½ê³  |
| `heap_used` | Heap ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ | 80% ì´ˆê³¼ ì‹œ ê²½ê³  |

#### 2. ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥
| ì§€í‘œ | ì„¤ëª… | ì„ê³„ê°’ |
|------|------|--------|
| `db_connection_pool_size` | í˜„ì¬ ì—°ê²° ìˆ˜ | ìµœëŒ€ì¹˜ì˜ 90% ì´ˆê³¼ ì‹œ ê²½ê³  |
| `db_query_duration` | ì¿¼ë¦¬ ì‹¤í–‰ ì‹œê°„ (ms) | 1000ms ì´ˆê³¼ ì‹œ slow query |
| `db_error_rate` | ë°ì´í„°ë² ì´ìŠ¤ ì—ëŸ¬ ë¹„ìœ¨ | 5% ì´ˆê³¼ ì‹œ ì•Œë¦¼ |

#### 3. Redis í ìƒíƒœ
| ì§€í‘œ | ì„¤ëª… | ì„ê³„ê°’ |
|------|------|--------|
| `redis_connection_status` | Redis ì—°ê²° ìƒíƒœ | 0ì´ë©´ ì•Œë¦¼ |
| `redis_memory_usage` | Redis ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ | 80% ì´ˆê³¼ ì‹œ ê²½ê³  |

### B. ì• í”Œë¦¬ì¼€ì´ì…˜ ì§€í‘œ (Application Metrics)

#### 4. API ì„±ëŠ¥
| ì§€í‘œ | ì„¤ëª… | ì„ê³„ê°’ |
|------|------|--------|
| `http_request_total` | HTTP ìš”ì²­ ìˆ˜ (ë¼ë²¨: method, path, status) | - |
| `http_request_duration` | API ì‘ë‹µ ì‹œê°„ (ms) | p95 > 3000ms ì‹œ ê²½ê³  |
| `http_request_error_rate` | API ì—ëŸ¬ ë¹„ìœ¨ (%) | 5% ì´ˆê³¼ ì‹œ ì•Œë¦¼ |
| `websocket_connections` | í™œì„± WebSocket ì—°ê²° ìˆ˜ | - |

#### 5. í¬ë¡¤ë§ ì‘ì—… ì§€í‘œ
| ì§€í‘œ | ì„¤ëª… | ì„ê³„ê°’ |
|------|------|--------|
| `crawl_jobs_total` | í¬ë¡¤ë§ ì‘ì—… ìˆ˜ (ë¼ë²¨: status) | - |
| `crawl_jobs_waiting` | ëŒ€ê¸° ì¤‘ì¸ ì‘ì—… ìˆ˜ | 100ê°œ ì´ˆê³¼ ì‹œ ê²½ê³  |
| `crawl_jobs_active` | ì‹¤í–‰ ì¤‘ì¸ ì‘ì—… ìˆ˜ | - |
| `crawl_jobs_completed` | ì™„ë£Œëœ ì‘ì—… ìˆ˜ | - |
| `crawl_jobs_failed` | ì‹¤íŒ¨í•œ ì‘ì—… ìˆ˜ | - |
| `crawl_job_duration` | í¬ë¡¤ë§ ì†Œìš” ì‹œê°„ (ms) | p95 > 30000ms ì‹œ ê²½ê³  |
| `crawl_success_rate` | í¬ë¡¤ë§ ì„±ê³µë¥  (%) | 90% ë¯¸ë§Œ ì‹œ ê²½ê³  |
| `crawl_retry_count` | ì¬ì‹œë„ íšŸìˆ˜ | - |

#### 6. Puppeteer ë¸Œë¼ìš°ì € ì§€í‘œ
| ì§€í‘œ | ì„¤ëª… | ì„ê³„ê°’ |
|------|------|--------|
| `browser_instance_count` | ë¸Œë¼ìš°ì € ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ | 5ê°œ ì´ˆê³¼ ì‹œ ê²½ê³  (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜) |
| `browser_page_count` | ì—´ë¦° í˜ì´ì§€ ìˆ˜ | 10ê°œ ì´ˆê³¼ ì‹œ ê²½ê³  |
| `browser_context_count` | Incognito ì»¨í…ìŠ¤íŠ¸ ìˆ˜ | 10ê°œ ì´ˆê³¼ ì‹œ ê²½ê³  |
| `browser_crash_count` | ë¸Œë¼ìš°ì € í¬ë˜ì‹œ íšŸìˆ˜ | 1íšŒ ì´ìƒ ì‹œ ì•Œë¦¼ |

#### 7. ìŠ¤ì¼€ì¤„ëŸ¬ ì§€í‘œ
| ì§€í‘œ | ì„¤ëª… | ì„ê³„ê°’ |
|------|------|--------|
| `scheduler_execution_count` | ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰ íšŸìˆ˜ | - |
| `scheduler_keywords_processed` | ì²˜ë¦¬ëœ í‚¤ì›Œë“œ ìˆ˜ | - |
| `scheduler_last_run_timestamp` | ë§ˆì§€ë§‰ ì‹¤í–‰ ì‹œê°„ | í˜„ì¬ ì‹œê°„ - 120ì´ˆ ì´ˆê³¼ ì‹œ ì•Œë¦¼ |

### C. ë¹„ì¦ˆë‹ˆìŠ¤ ì§€í‘œ (Business Metrics)

#### 8. í‚¤ì›Œë“œ ê´€ë¦¬
| ì§€í‘œ | ì„¤ëª… | ì„ê³„ê°’ |
|------|------|--------|
| `keywords_total` | ë“±ë¡ëœ ì´ í‚¤ì›Œë“œ ìˆ˜ | - |
| `keywords_active` | í™œì„± í‚¤ì›Œë“œ ìˆ˜ | - |
| `rank_alerts_sent` | ë°œì†¡ëœ ìˆœìœ„ ì•Œë¦¼ ìˆ˜ | - |
| `rank_changes_detected` | ìˆœìœ„ ë³€ë™ ê°ì§€ ìˆ˜ | - |

#### 9. ë°ì´í„° í’ˆì§ˆ
| ì§€í‘œ | ì„¤ëª… | ì„ê³„ê°’ |
|------|------|--------|
| `rank_null_rate` | ìˆœìœ„ë¥¼ ì°¾ì§€ ëª»í•œ ë¹„ìœ¨ (%) | 20% ì´ˆê³¼ ì‹œ í¬ë¡¤ë§ ë¡œì§ ì ê²€ |
| `stale_keywords_count` | 24ì‹œê°„ ì´ìƒ ë¯¸í™•ì¸ í‚¤ì›Œë“œ ìˆ˜ | 10% ì´ˆê³¼ ì‹œ ìŠ¤ì¼€ì¤„ëŸ¬ ì ê²€ |

---

## ğŸ› ï¸ ëª¨ë‹ˆí„°ë§ ë°©ì•ˆ

### 1. ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë„êµ¬: Prometheus + Grafana (ì¶”ì²œ)

#### ì„ ì • ì´ìœ 
- **ì˜¤í”ˆì†ŒìŠ¤**: ë¬´ë£Œ, ì»¤ë®¤ë‹ˆí‹° í™œì„±í™”
- **Node.js ì§€ì›**: `prom-client` ë¼ì´ë¸ŒëŸ¬ë¦¬ ì•ˆì •ì„± ë†’ìŒ
- **Pull ë°©ì‹**: ì• í”Œë¦¬ì¼€ì´ì…˜ ë¶€ë‹´ ìµœì†Œí™”
- **ì‹œê°í™”**: Grafana ëŒ€ì‹œë³´ë“œ ê°•ë ¥í•¨
- **ì•Œë¦¼**: Alertmanager í†µí•©
- **Docker ì§€ì›**: ê¸°ì¡´ docker-composeì— ì‰½ê²Œ ì¶”ê°€

#### ì•„í‚¤í…ì²˜
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Server     â”‚â”€â”€â”
â”‚  (Express)      â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Worker x2      â”‚â”€â”€â”¼â”€â”€>â”‚  Prometheus  â”‚â”€â”€â”€>â”‚   Grafana    â”‚
â”‚  (Puppeteer)    â”‚  â”‚   â”‚  (Metrics)   â”‚    â”‚ (Dashboard)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚          â”‚
â”‚  Scheduler      â”‚â”€â”€â”˜          v
â”‚  (Cron)         â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚ Alertmanager â”‚
                          â”‚  (Alerts)    â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. ë¡œê¹… ê°œì„ : Winston êµ¬ì¡°í™” ë¡œê¹…

#### í˜„ì¬ ë¬¸ì œì 
- console.logë§Œ ì‚¬ìš© ì¤‘ (Winston ì„¤ì¹˜ëì§€ë§Œ ë¯¸ì‚¬ìš©)
- êµ¬ì¡°í™”ë˜ì§€ ì•Šì€ ë¡œê·¸
- ë¡œê·¸ ë ˆë²¨ êµ¬ë¶„ ì—†ìŒ
- ì¤‘ì•™ ì§‘ì¤‘ì‹ ë¡œê·¸ ê´€ë¦¬ ë¶ˆê°€

#### ê°œì„  ë°©ì•ˆ
```typescript
// Winston ë¡œê±° ì„¤ì •
// - JSON í˜•ì‹ (êµ¬ì¡°í™”)
// - íƒ€ì„ìŠ¤íƒ¬í”„ ìë™ ì¶”ê°€
// - ë ˆë²¨ë³„ ìƒ‰ìƒ êµ¬ë¶„ (development)
// - íŒŒì¼ ë¡œí…Œì´ì…˜ (production)
// - ì—ëŸ¬ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ í¬í•¨
```

**ë¡œê·¸ ë ˆë²¨ ì „ëµ:**
- `error`: ì¦‰ì‹œ ëŒ€ì‘ í•„ìš” (í¬ë¡¤ë§ ì‹¤íŒ¨, DB ì—ëŸ¬)
- `warn`: ì£¼ì˜ í•„ìš” (ì¬ì‹œë„, ì„ê³„ê°’ ê·¼ì ‘)
- `info`: ì¼ë°˜ ì •ë³´ (ì‘ì—… ì™„ë£Œ, ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰)
- `debug`: ë””ë²„ê¹… ì •ë³´ (ìƒì„¸ í¬ë¡¤ë§ ë‹¨ê³„)

### 3. ì¶”ì  ì‹œìŠ¤í…œ: OpenTelemetry (ì„ íƒì‚¬í•­)

ë¶„ì‚° ì¶”ì ì„ í†µí•´ í¬ë¡¤ë§ ì‘ì—…ì˜ ì „ì²´ ë¼ì´í”„ì‚¬ì´í´ ì¶”ì :
```
API Request â†’ Queue Enqueue â†’ Worker Processing â†’ Crawling â†’ DB Save â†’ WebSocket Emit
    1ms           5ms              2000ms          25000ms     10ms        2ms
```

---

## ğŸ’» ì½”ë“œ ì ìš© ìƒ˜í”Œ

### ìƒ˜í”Œ 1: Prometheus ë©”íŠ¸ë¦­ ì„¤ì •

#### `/backend/src/monitoring/metrics.ts` (ì‹ ê·œ íŒŒì¼)

```typescript
import client from 'prom-client';

// ê¸°ë³¸ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (CPU, Memory, Event Loop ë“±)
client.collectDefaultMetrics({ timeout: 5000 });

// === ì¸í”„ë¼ ë©”íŠ¸ë¦­ ===
export const appUptime = new client.Gauge({
  name: 'app_uptime_seconds',
  help: 'Application uptime in seconds',
});

export const memoryUsage = new client.Gauge({
  name: 'app_memory_usage_bytes',
  help: 'Memory usage in bytes',
  labelNames: ['type'], // rss, heapTotal, heapUsed, external
});

export const dbConnectionPoolSize = new client.Gauge({
  name: 'db_connection_pool_size',
  help: 'Current number of database connections',
  labelNames: ['state'], // idle, active
});

export const dbQueryDuration = new client.Histogram({
  name: 'db_query_duration_ms',
  help: 'Database query duration in milliseconds',
  labelNames: ['query_type'], // select, insert, update, delete
  buckets: [10, 50, 100, 300, 500, 1000, 3000, 5000],
});

export const redisConnectionStatus = new client.Gauge({
  name: 'redis_connection_status',
  help: 'Redis connection status (1 = connected, 0 = disconnected)',
});

// === API ë©”íŠ¸ë¦­ ===
export const httpRequestTotal = new client.Counter({
  name: 'http_requests_total',
  help: 'Total number of HTTP requests',
  labelNames: ['method', 'path', 'status'],
});

export const httpRequestDuration = new client.Histogram({
  name: 'http_request_duration_ms',
  help: 'HTTP request duration in milliseconds',
  labelNames: ['method', 'path'],
  buckets: [50, 100, 300, 500, 1000, 3000, 5000, 10000],
});

export const websocketConnections = new client.Gauge({
  name: 'websocket_connections_active',
  help: 'Number of active WebSocket connections',
});

// === í¬ë¡¤ë§ ì‘ì—… ë©”íŠ¸ë¦­ ===
export const crawlJobsTotal = new client.Counter({
  name: 'crawl_jobs_total',
  help: 'Total number of crawl jobs',
  labelNames: ['status'], // completed, failed, retried
});

export const crawlJobsWaiting = new client.Gauge({
  name: 'crawl_jobs_waiting',
  help: 'Number of jobs waiting in queue',
});

export const crawlJobsActive = new client.Gauge({
  name: 'crawl_jobs_active',
  help: 'Number of jobs currently being processed',
});

export const crawlJobDuration = new client.Histogram({
  name: 'crawl_job_duration_ms',
  help: 'Crawl job duration in milliseconds',
  labelNames: ['keyword_id'],
  buckets: [5000, 10000, 15000, 20000, 25000, 30000, 45000, 60000],
});

export const crawlSuccessRate = new client.Gauge({
  name: 'crawl_success_rate',
  help: 'Crawl job success rate (0-1)',
});

export const crawlRetryCount = new client.Counter({
  name: 'crawl_retry_total',
  help: 'Total number of crawl job retries',
  labelNames: ['keyword_id', 'attempt'],
});

// === Puppeteer ë¸Œë¼ìš°ì € ë©”íŠ¸ë¦­ ===
export const browserInstanceCount = new client.Gauge({
  name: 'browser_instance_count',
  help: 'Number of Puppeteer browser instances',
});

export const browserPageCount = new client.Gauge({
  name: 'browser_page_count',
  help: 'Number of open browser pages',
});

export const browserContextCount = new client.Gauge({
  name: 'browser_context_count',
  help: 'Number of browser contexts',
});

export const browserCrashCount = new client.Counter({
  name: 'browser_crash_total',
  help: 'Total number of browser crashes',
});

// === ìŠ¤ì¼€ì¤„ëŸ¬ ë©”íŠ¸ë¦­ ===
export const schedulerExecutionCount = new client.Counter({
  name: 'scheduler_execution_total',
  help: 'Total number of scheduler executions',
});

export const schedulerKeywordsProcessed = new client.Counter({
  name: 'scheduler_keywords_processed_total',
  help: 'Total number of keywords processed by scheduler',
});

export const schedulerLastRunTimestamp = new client.Gauge({
  name: 'scheduler_last_run_timestamp',
  help: 'Unix timestamp of last scheduler execution',
});

// === ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­ ===
export const keywordsTotal = new client.Gauge({
  name: 'keywords_total',
  help: 'Total number of registered keywords',
});

export const rankAlertsTotal = new client.Counter({
  name: 'rank_alerts_total',
  help: 'Total number of rank alerts sent',
  labelNames: ['keyword_id'],
});

export const rankNullRate = new client.Gauge({
  name: 'rank_null_rate',
  help: 'Rate of crawls that did not find ranking (0-1)',
});

// ë©”íŠ¸ë¦­ ë ˆì§€ìŠ¤íŠ¸ë¦¬ export
export const register = client.register;
```

---

### ìƒ˜í”Œ 2: API ì„œë²„ì— Prometheus ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€

#### `/backend/src/api/server.ts` ìˆ˜ì •

```typescript
import express from "express";
import cors from "cors";
import { createServer } from "http";
import swaggerUi from "swagger-ui-express";
import swaggerDocument from "./swagger";
import keywordsRouter from "./routes/keywords";
import rankingsRouter from "./routes/rankings";
import jobsRouter from "./routes/jobs";
import { pool } from "../db/connection";
import { register, httpRequestTotal, httpRequestDuration } from "../monitoring/metrics";

const app = express();
const PORT = process.env.PORT || 3000;

app.use(cors());
app.use(express.json());

// === ëª¨ë‹ˆí„°ë§ ë¯¸ë“¤ì›¨ì–´ ===
app.use((req, res, next) => {
  const start = Date.now();

  res.on('finish', () => {
    const duration = Date.now() - start;

    // HTTP ìš”ì²­ ì¹´ìš´í„°
    httpRequestTotal.inc({
      method: req.method,
      path: req.route?.path || req.path,
      status: res.statusCode,
    });

    // HTTP ìš”ì²­ ì§€ì† ì‹œê°„
    httpRequestDuration.observe(
      {
        method: req.method,
        path: req.route?.path || req.path,
      },
      duration
    );
  });

  next();
});

// === API ë¼ìš°íŠ¸ ===
app.use("/api/keywords", keywordsRouter);
app.use("/api/rankings", rankingsRouter);
app.use("/api/jobs", jobsRouter);
app.use("/api-docs", swaggerUi.serve, swaggerUi.setup(swaggerDocument));

// === Health Check ===
app.get("/health", async (req, res) => {
  try {
    await pool.query("SELECT 1");
    res.json({
      status: "ok",
      timestamp: new Date().toISOString(),
      uptime: process.uptime(),
    });
  } catch (error) {
    res.status(503).json({
      status: "error",
      message: "Database connection failed"
    });
  }
});

// === Prometheus ë©”íŠ¸ë¦­ ì—”ë“œí¬ì¸íŠ¸ ===
app.get("/metrics", async (req, res) => {
  res.set("Content-Type", register.contentType);
  res.end(await register.metrics());
});

// === ì„œë²„ ì‹œì‘ ===
const httpServer = createServer(app);

httpServer.listen(PORT, () => {
  console.log(`API Server running on port ${PORT}`);
  console.log(`Metrics available at http://localhost:${PORT}/metrics`);
});

export { app, httpServer };
```

---

### ìƒ˜í”Œ 3: Workerì—ì„œ í¬ë¡¤ë§ ë©”íŠ¸ë¦­ ìˆ˜ì§‘

#### `/backend/src/worker/processor.ts` ìˆ˜ì •

```typescript
import { Job } from "bull";
import { crawlQueue } from "../queue/crawlQueue";
import { crawlSearchResult } from "./crawler";
import { saveRanking } from "../db/queries";
import {
  crawlJobsTotal,
  crawlJobsActive,
  crawlJobDuration,
  crawlRetryCount,
} from "../monitoring/metrics";

const CONCURRENCY = parseInt(process.env.WORKER_CONCURRENCY || "2", 10);

crawlQueue.process(CONCURRENCY, async (job: Job) => {
  const startTime = Date.now();
  const { keyword, targetUrl, keywordId } = job.data;

  // í™œì„± ì‘ì—… ìˆ˜ ì¦ê°€
  crawlJobsActive.inc();

  try {
    console.log(`[Worker ${process.pid}] Processing job ${job.id}: ${keyword}`);

    // ì§„í–‰ë¥  10%
    await job.progress(10);

    // í¬ë¡¤ë§ ì‹¤í–‰
    const rank = await crawlSearchResult(keyword, targetUrl);

    // ì§„í–‰ë¥  80%
    await job.progress(80);

    // ìˆœìœ„ ì €ì¥
    await saveRanking(keywordId, rank);

    // ì§„í–‰ë¥  100%
    await job.progress(100);

    const duration = Date.now() - startTime;
    console.log(`[Worker ${process.pid}] Job ${job.id} completed. Rank: ${rank}, Duration: ${duration}ms`);

    // === ë©”íŠ¸ë¦­ ê¸°ë¡ ===
    crawlJobsTotal.inc({ status: 'completed' });
    crawlJobDuration.observe({ keyword_id: keywordId }, duration);

    // ì¬ì‹œë„ íšŸìˆ˜ ê¸°ë¡
    if (job.attemptsMade > 1) {
      crawlRetryCount.inc({
        keyword_id: keywordId,
        attempt: job.attemptsMade.toString(),
      });
      crawlJobsTotal.inc({ status: 'retried' });
    }

    return { rank, keywordId, keyword };
  } catch (error) {
    const duration = Date.now() - startTime;
    console.error(`[Worker ${process.pid}] Job ${job.id} failed:`, error);

    // === ì‹¤íŒ¨ ë©”íŠ¸ë¦­ ê¸°ë¡ ===
    crawlJobsTotal.inc({ status: 'failed' });
    crawlJobDuration.observe({ keyword_id: keywordId }, duration);

    throw error;
  } finally {
    // í™œì„± ì‘ì—… ìˆ˜ ê°ì†Œ
    crawlJobsActive.dec();
  }
});

console.log(`Worker ${process.pid} started with concurrency ${CONCURRENCY}`);
```

---

### ìƒ˜í”Œ 4: Puppeteer ë¸Œë¼ìš°ì € ë©”íŠ¸ë¦­ ì¶”ì 

#### `/backend/src/worker/crawler.ts` ìˆ˜ì •

```typescript
import puppeteer, { Browser, Page } from "puppeteer";
import {
  browserInstanceCount,
  browserPageCount,
  browserContextCount,
  browserCrashCount,
} from "../monitoring/metrics";

let browser: Browser | null = null;

async function getBrowser(): Promise<Browser> {
  if (!browser || !browser.isConnected()) {
    console.log("[Crawler] Launching new browser instance");
    browser = await puppeteer.launch({
      headless: true,
      args: ["--no-sandbox", "--disable-setuid-sandbox"],
    });

    // ë¸Œë¼ìš°ì € ì¸ìŠ¤í„´ìŠ¤ ì¹´ìš´íŠ¸
    browserInstanceCount.inc();

    // ë¸Œë¼ìš°ì € í¬ë˜ì‹œ ê°ì§€
    browser.on('disconnected', () => {
      console.error("[Crawler] Browser crashed or disconnected");
      browserCrashCount.inc();
      browserInstanceCount.dec();
      browser = null;
    });
  }
  return browser;
}

export async function crawlSearchResult(
  keyword: string,
  targetUrl: string
): Promise<number | null> {
  const searchUrl = `https://m.ad.search.naver.com/search.naver?query=${encodeURIComponent(
    keyword
  )}`;

  const browserInstance = await getBrowser();
  const context = await browserInstance.createIncognitoBrowserContext();
  browserContextCount.inc();

  let page: Page | null = null;

  try {
    page = await context.newPage();
    browserPageCount.inc();

    // ëª¨ë°”ì¼ User-Agent ì„¤ì •
    await page.setUserAgent(
      "Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X) AppleWebKit/605.1.15"
    );

    console.log(`[Crawler] Navigating to search result for: ${keyword}`);
    await page.goto(searchUrl, { waitUntil: "networkidle0", timeout: 30000 });
    await new Promise((resolve) => setTimeout(resolve, 2000));

    const rank = await page.evaluate((url: string) => {
      const items = document.querySelectorAll("li.list_item");
      for (let i = 0; i < items.length; i++) {
        const titleEl = items[i].querySelector(".tit_area .tit") as HTMLElement;
        const urlEl = items[i].querySelector(".url_link") as HTMLElement;

        if (!titleEl || !urlEl) continue;

        const title = titleEl.innerText || "";
        const displayUrl = urlEl.innerText || "";

        if (displayUrl.includes(url) || title.includes(url)) {
          return i + 1;
        }
      }
      return null;
    }, targetUrl);

    console.log(`[Crawler] Rank for "${keyword}": ${rank}`);
    return rank;
  } catch (error) {
    console.error(`[Crawler] Error crawling keyword "${keyword}":`, error);
    throw error;
  } finally {
    if (page) {
      await page.close();
      browserPageCount.dec();
    }
    await context.close();
    browserContextCount.dec();
  }
}

export async function closeBrowser(): Promise<void> {
  if (browser) {
    await browser.close();
    browserInstanceCount.dec();
    browser = null;
  }
}
```

---

### ìƒ˜í”Œ 5: ìŠ¤ì¼€ì¤„ëŸ¬ ë©”íŠ¸ë¦­ ì¶”ì 

#### `/backend/src/scheduler/index.ts` ìˆ˜ì •

```typescript
import cron from "node-cron";
import { getAllKeywords } from "../db/queries";
import { crawlQueue } from "../queue/crawlQueue";
import {
  schedulerExecutionCount,
  schedulerKeywordsProcessed,
  schedulerLastRunTimestamp,
  crawlJobsWaiting,
} from "../monitoring/metrics";

const CRON_SCHEDULE = process.env.CRON_SCHEDULE || "* * * * *";
const RECHECK_THRESHOLD_MS = 60000;

console.log(`[Scheduler] Starting with schedule: ${CRON_SCHEDULE}`);

cron.schedule(CRON_SCHEDULE, async () => {
  const executionStart = Date.now();
  console.log(`[Scheduler] Running at ${new Date().toISOString()}`);

  // ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰ ì¹´ìš´íŠ¸
  schedulerExecutionCount.inc();
  schedulerLastRunTimestamp.set(Date.now() / 1000); // Unix timestamp

  try {
    const keywords = await getAllKeywords();
    console.log(`[Scheduler] Found ${keywords.length} keywords to check.`);

    const now = Date.now();
    let enqueuedCount = 0;

    for (const kw of keywords) {
      const lastChecked = kw.last_checked_at
        ? new Date(kw.last_checked_at).getTime()
        : 0;

      if (now - lastChecked < RECHECK_THRESHOLD_MS) {
        continue;
      }

      let shouldEnqueue = false;
      const existingJob = await crawlQueue.getJob(kw.id);

      if (!existingJob) {
        shouldEnqueue = true;
      } else {
        const state = await existingJob.getState();
        if (state === "completed" || state === "failed") {
          shouldEnqueue = true;
        } else if (state === "stuck") {
          console.log(`[Scheduler] Removing stuck job for keyword ${kw.id}`);
          await existingJob.remove();
          shouldEnqueue = true;
        }
      }

      if (shouldEnqueue) {
        await crawlQueue.add(
          {
            keywordId: kw.id,
            keyword: kw.keyword,
            targetUrl: kw.url,
          },
          {
            jobId: kw.id,
            priority: 10,
          }
        );
        enqueuedCount++;
      }
    }

    // ëŒ€ê¸° ì¤‘ì¸ ì‘ì—… ìˆ˜ ì—…ë°ì´íŠ¸
    const waitingJobs = await crawlQueue.getWaiting();
    crawlJobsWaiting.set(waitingJobs.length);

    // ì²˜ë¦¬ëœ í‚¤ì›Œë“œ ìˆ˜ ê¸°ë¡
    schedulerKeywordsProcessed.inc(enqueuedCount);

    const duration = Date.now() - executionStart;
    console.log(
      `[Scheduler] Enqueued ${enqueuedCount} jobs in ${duration}ms. Waiting: ${waitingJobs.length}`
    );
  } catch (error) {
    console.error("[Scheduler] Error during execution:", error);
  }
});
```

---

### ìƒ˜í”Œ 6: Winston êµ¬ì¡°í™” ë¡œê¹… ì„¤ì •

#### `/backend/src/monitoring/logger.ts` (ì‹ ê·œ íŒŒì¼)

```typescript
import winston from "winston";

const isProduction = process.env.NODE_ENV === "production";

// ì»¤ìŠ¤í…€ í¬ë§·: íƒ€ì„ìŠ¤íƒ¬í”„ + ë ˆë²¨ + ë©”ì‹œì§€ + ë©”íƒ€ë°ì´í„°
const customFormat = winston.format.combine(
  winston.format.timestamp({ format: "YYYY-MM-DD HH:mm:ss" }),
  winston.format.errors({ stack: true }),
  winston.format.splat(),
  winston.format.json()
);

// Console ì¶œë ¥ í¬ë§· (ê°œë°œ í™˜ê²½)
const consoleFormat = winston.format.combine(
  winston.format.colorize(),
  winston.format.timestamp({ format: "HH:mm:ss" }),
  winston.format.printf(({ timestamp, level, message, service, ...meta }) => {
    const metaString = Object.keys(meta).length
      ? `\n${JSON.stringify(meta, null, 2)}`
      : "";
    return `${timestamp} [${service || "app"}] ${level}: ${message}${metaString}`;
  })
);

// ë¡œê±° ìƒì„±
export const logger = winston.createLogger({
  level: process.env.LOG_LEVEL || (isProduction ? "info" : "debug"),
  format: customFormat,
  defaultMeta: { service: "charles-monitor" },
  transports: [
    // Console ì¶œë ¥
    new winston.transports.Console({
      format: isProduction ? customFormat : consoleFormat,
    }),

    // íŒŒì¼ ì¶œë ¥ (production)
    ...(isProduction
      ? [
          // ëª¨ë“  ë¡œê·¸
          new winston.transports.File({
            filename: "logs/combined.log",
            maxsize: 10485760, // 10MB
            maxFiles: 5,
          }),

          // ì—ëŸ¬ ë¡œê·¸ë§Œ
          new winston.transports.File({
            filename: "logs/error.log",
            level: "error",
            maxsize: 10485760,
            maxFiles: 5,
          }),
        ]
      : []),
  ],
  exceptionHandlers: [
    new winston.transports.File({ filename: "logs/exceptions.log" }),
  ],
  rejectionHandlers: [
    new winston.transports.File({ filename: "logs/rejections.log" }),
  ],
});

// console.log ëŒ€ì²´ í—¬í¼ í•¨ìˆ˜
export const log = {
  error: (message: string, meta?: any) => logger.error(message, meta),
  warn: (message: string, meta?: any) => logger.warn(message, meta),
  info: (message: string, meta?: any) => logger.info(message, meta),
  debug: (message: string, meta?: any) => logger.debug(message, meta),
};
```

#### ì‚¬ìš© ì˜ˆì‹œ: `/backend/src/worker/processor.ts`

```typescript
// Before
console.log(`[Worker ${process.pid}] Processing job ${job.id}: ${keyword}`);

// After
import { log } from "../monitoring/logger";

log.info("Processing crawl job", {
  service: "worker",
  workerId: process.pid,
  jobId: job.id,
  keyword,
  keywordId,
  attemptsMade: job.attemptsMade,
});
```

---

### ìƒ˜í”Œ 7: Docker Composeì— Prometheus & Grafana ì¶”ê°€

#### `/docker-compose.yml` ìˆ˜ì •

```yaml
version: "3.8"

services:
  postgres:
    image: postgres:16
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: charles_monitor
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  api:
    build:
      context: ./backend
      dockerfile: Dockerfile
    command: npm run start:api
    ports:
      - "3000:3000"
    environment:
      DATABASE_URL: postgresql://postgres:postgres@postgres:5432/charles_monitor
      REDIS_URL: redis://redis:6379
      PORT: 3000
      NODE_ENV: production
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy

  worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    command: npm run start:worker
    environment:
      DATABASE_URL: postgresql://postgres:postgres@postgres:5432/charles_monitor
      REDIS_URL: redis://redis:6379
      WORKER_CONCURRENCY: 2
      NODE_ENV: production
    depends_on:
      - postgres
      - redis
      - api
    deploy:
      replicas: 2  # ì›Œì»¤ 2ê°œ ì¸ìŠ¤í„´ìŠ¤

  scheduler:
    build:
      context: ./backend
      dockerfile: Dockerfile
    command: npm run start:scheduler
    environment:
      DATABASE_URL: postgresql://postgres:postgres@postgres:5432/charles_monitor
      REDIS_URL: redis://redis:6379
      CRON_SCHEDULE: "* * * * *"
      NODE_ENV: production
    depends_on:
      - postgres
      - redis

  # === ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ===
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--web.console.libraries=/usr/share/prometheus/console_libraries"
      - "--web.console.templates=/usr/share/prometheus/consoles"
    depends_on:
      - api
      - worker
      - scheduler

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3001:3000"
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
      GF_INSTALL_PLUGINS: grafana-piechart-panel
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    depends_on:
      - prometheus

  alertmanager:
    image: prom/alertmanager:latest
    ports:
      - "9093:9093"
    volumes:
      - ./monitoring/alertmanager.yml:/etc/alertmanager/alertmanager.yml
      - alertmanager_data:/alertmanager
    command:
      - "--config.file=/etc/alertmanager/alertmanager.yml"
      - "--storage.path=/alertmanager"
    depends_on:
      - prometheus

volumes:
  postgres_data:
  redis_data:
  prometheus_data:
  grafana_data:
  alertmanager_data:
```

---

### ìƒ˜í”Œ 8: Prometheus ì„¤ì • íŒŒì¼

#### `/monitoring/prometheus.yml` (ì‹ ê·œ íŒŒì¼)

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

# Alertmanager ì„¤ì •
alerting:
  alertmanagers:
    - static_configs:
        - targets:
            - alertmanager:9093

# ì•Œë¦¼ ê·œì¹™ íŒŒì¼
rule_files:
  - "/etc/prometheus/alerts.yml"

# ìŠ¤í¬ë© ëŒ€ìƒ
scrape_configs:
  # API ì„œë²„ ë©”íŠ¸ë¦­
  - job_name: "api"
    static_configs:
      - targets: ["api:3000"]
    metrics_path: "/metrics"

  # Worker ë©”íŠ¸ë¦­ (2ê°œ ì¸ìŠ¤í„´ìŠ¤)
  - job_name: "worker"
    static_configs:
      - targets:
          - "worker:3000"  # Docker ComposeëŠ” ìë™ìœ¼ë¡œ ë¡œë“œë°¸ëŸ°ì‹±
    metrics_path: "/metrics"

  # Scheduler ë©”íŠ¸ë¦­
  - job_name: "scheduler"
    static_configs:
      - targets: ["scheduler:3000"]
    metrics_path: "/metrics"

  # Prometheus ìì²´ ë©”íŠ¸ë¦­
  - job_name: "prometheus"
    static_configs:
      - targets: ["localhost:9090"]
```

---

### ìƒ˜í”Œ 9: Alertmanager ì•Œë¦¼ ê·œì¹™

#### `/monitoring/alerts.yml` (ì‹ ê·œ íŒŒì¼)

```yaml
groups:
  - name: charles_monitor_alerts
    interval: 30s
    rules:
      # API ì„œë²„ ë‹¤ìš´
      - alert: APIServerDown
        expr: up{job="api"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "API ì„œë²„ê°€ ë‹¤ìš´ë˜ì—ˆìŠµë‹ˆë‹¤"
          description: "API ì„œë²„ê°€ 1ë¶„ ì´ìƒ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."

      # í¬ë¡¤ë§ ì„±ê³µë¥  ì €í•˜
      - alert: LowCrawlSuccessRate
        expr: crawl_success_rate < 0.9
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "í¬ë¡¤ë§ ì„±ê³µë¥ ì´ ë‚®ìŠµë‹ˆë‹¤"
          description: "í¬ë¡¤ë§ ì„±ê³µë¥ ì´ {{ $value }}% ì…ë‹ˆë‹¤ (ëª©í‘œ: 90%)."

      # ëŒ€ê¸° ì‘ì—… ìˆ˜ ê³¼ë‹¤
      - alert: HighQueueWaiting
        expr: crawl_jobs_waiting > 100
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "ëŒ€ê¸° ì¤‘ì¸ í¬ë¡¤ë§ ì‘ì—…ì´ ë§ìŠµë‹ˆë‹¤"
          description: "{{ $value }}ê°œì˜ ì‘ì—…ì´ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤."

      # API ì‘ë‹µ ì‹œê°„ ì§€ì—°
      - alert: SlowAPIResponse
        expr: histogram_quantile(0.95, http_request_duration_ms_bucket) > 3000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "API ì‘ë‹µ ì‹œê°„ì´ ëŠë¦½ë‹ˆë‹¤"
          description: "95 ë°±ë¶„ìœ„ ì‘ë‹µ ì‹œê°„ì´ {{ $value }}msì…ë‹ˆë‹¤."

      # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë†’ìŒ
      - alert: HighMemoryUsage
        expr: (process_resident_memory_bytes / 1024 / 1024) > 512
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤"
          description: "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ {{ $value }}MBì…ë‹ˆë‹¤."

      # ë¸Œë¼ìš°ì € í¬ë˜ì‹œ ë°œìƒ
      - alert: BrowserCrashed
        expr: increase(browser_crash_total[5m]) > 0
        labels:
          severity: critical
        annotations:
          summary: "Puppeteer ë¸Œë¼ìš°ì €ê°€ í¬ë˜ì‹œí–ˆìŠµë‹ˆë‹¤"
          description: "ìµœê·¼ 5ë¶„ê°„ {{ $value }}íšŒ í¬ë˜ì‹œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

      # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰ ì§€ì—°
      - alert: SchedulerNotRunning
        expr: (time() - scheduler_last_run_timestamp) > 120
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì‹¤í–‰ë˜ì§€ ì•Šê³  ìˆìŠµë‹ˆë‹¤"
          description: "ë§ˆì§€ë§‰ ì‹¤í–‰ í›„ {{ $value }}ì´ˆê°€ ê²½ê³¼í–ˆìŠµë‹ˆë‹¤."

      # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ë¶€ì¡±
      - alert: DatabaseConnectionPoolExhausted
        expr: db_connection_pool_size{state="active"} > 8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ì´ ë¶€ì¡±í•©ë‹ˆë‹¤"
          description: "í™œì„± ì—°ê²° ìˆ˜ê°€ {{ $value }}ê°œì…ë‹ˆë‹¤ (ìµœëŒ€: 10)."
```

---

### ìƒ˜í”Œ 10: Alertmanager ì•Œë¦¼ ì „ì†¡ ì„¤ì •

#### `/monitoring/alertmanager.yml` (ì‹ ê·œ íŒŒì¼)

```yaml
global:
  resolve_timeout: 5m

# ì•Œë¦¼ ë¼ìš°íŒ…
route:
  group_by: ["alertname", "severity"]
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h
  receiver: "default"
  routes:
    - match:
        severity: critical
      receiver: "critical"
      repeat_interval: 1h

    - match:
        severity: warning
      receiver: "warning"
      repeat_interval: 4h

# ì•Œë¦¼ ìˆ˜ì‹ ì ì„¤ì •
receivers:
  # ê¸°ë³¸ ìˆ˜ì‹ ì (ì½˜ì†” ì¶œë ¥)
  - name: "default"
    webhook_configs:
      - url: "http://localhost:5001/webhook"

  # Critical ì•Œë¦¼ (ìŠ¬ë™, ì´ë©”ì¼ ë“±)
  - name: "critical"
    # Slack ì˜ˆì‹œ
    slack_configs:
      - api_url: "${SLACK_WEBHOOK_URL}"
        channel: "#alerts-critical"
        title: "ğŸš¨ Critical Alert"
        text: "{{ range .Alerts }}{{ .Annotations.summary }}\n{{ .Annotations.description }}\n{{ end }}"

    # Email ì˜ˆì‹œ
    # email_configs:
    #   - to: "team@example.com"
    #     from: "alertmanager@example.com"
    #     smarthost: "smtp.gmail.com:587"
    #     auth_username: "your-email@gmail.com"
    #     auth_password: "${SMTP_PASSWORD}"
    #     headers:
    #       Subject: "Critical Alert: {{ .GroupLabels.alertname }}"

  # Warning ì•Œë¦¼
  - name: "warning"
    slack_configs:
      - api_url: "${SLACK_WEBHOOK_URL}"
        channel: "#alerts-warning"
        title: "âš ï¸ Warning Alert"
        text: "{{ range .Alerts }}{{ .Annotations.summary }}\n{{ .Annotations.description }}\n{{ end }}"

# ì•Œë¦¼ ì–µì œ ê·œì¹™ (ì¤‘ë³µ ë°©ì§€)
inhibit_rules:
  - source_match:
      severity: "critical"
    target_match:
      severity: "warning"
    equal: ["alertname"]
```

---

## ğŸ“ˆ Grafana ëŒ€ì‹œë³´ë“œ ì˜ˆì‹œ

### ëŒ€ì‹œë³´ë“œ êµ¬ì„±

1. **System Overview**
   - CPU, Memory, Disk ì‚¬ìš©ë¥ 
   - API ì„œë²„ Uptime
   - Redis & PostgreSQL ì—°ê²° ìƒíƒœ

2. **API Performance**
   - ìš”ì²­ ìˆ˜ (QPS)
   - ì‘ë‹µ ì‹œê°„ (p50, p95, p99)
   - ì—ëŸ¬ìœ¨ (4xx, 5xx)
   - WebSocket ì—°ê²° ìˆ˜

3. **Crawling Jobs**
   - ì‘ì—… ìƒíƒœë³„ ë¶„í¬ (Waiting, Active, Completed, Failed)
   - ì‘ì—… ì²˜ë¦¬ ì‹œê°„ íˆìŠ¤í† ê·¸ë¨
   - ì„±ê³µë¥  íŠ¸ë Œë“œ
   - ì¬ì‹œë„ íšŸìˆ˜

4. **Browser Health**
   - ë¸Œë¼ìš°ì € ì¸ìŠ¤í„´ìŠ¤ ìˆ˜
   - í˜ì´ì§€/ì»¨í…ìŠ¤íŠ¸ ìˆ˜
   - í¬ë˜ì‹œ íšŸìˆ˜

5. **Business Metrics**
   - ë“±ë¡ëœ í‚¤ì›Œë“œ ìˆ˜
   - ìˆœìœ„ ì•Œë¦¼ ë°œì†¡ ìˆ˜
   - ìˆœìœ„ ë³€ë™ ê°ì§€ ìˆ˜
   - Null ìˆœìœ„ ë¹„ìœ¨

---

## ğŸš€ êµ¬í˜„ ë¡œë“œë§µ

### Phase 1: ê¸°ë³¸ ëª¨ë‹ˆí„°ë§ (1-2ì¼)
- [ ] Prometheus ë©”íŠ¸ë¦­ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (`prom-client`)
- [ ] ê¸°ë³¸ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì½”ë“œ ì‘ì„±
- [ ] API `/metrics` ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
- [ ] Winston ë¡œê±° ì„¤ì • ë° console.log êµì²´

### Phase 2: ì¸í”„ë¼ ì„¤ì • (1ì¼)
- [ ] Docker Composeì— Prometheus, Grafana ì¶”ê°€
- [ ] Prometheus ìŠ¤í¬ë© ì„¤ì •
- [ ] Grafana ë°ì´í„°ì†ŒìŠ¤ ì—°ê²°

### Phase 3: ëŒ€ì‹œë³´ë“œ & ì•Œë¦¼ (1-2ì¼)
- [ ] Grafana ëŒ€ì‹œë³´ë“œ ìƒì„±
- [ ] Alertmanager ì•Œë¦¼ ê·œì¹™ ì‘ì„±
- [ ] Slack/Email ì•Œë¦¼ ì—°ë™ í…ŒìŠ¤íŠ¸

### Phase 4: ê³ ë„í™” (ì„ íƒì‚¬í•­)
- [ ] OpenTelemetry ë¶„ì‚° ì¶”ì  ì¶”ê°€
- [ ] ELK Stack ë¡œê·¸ ì§‘ê³„ (Elasticsearch, Logstash, Kibana)
- [ ] APM ë„êµ¬ ì—°ë™ (New Relic, Datadog ë“±)

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [Prometheus Documentation](https://prometheus.io/docs/)
- [Grafana Documentation](https://grafana.com/docs/)
- [prom-client GitHub](https://github.com/siimon/prom-client)
- [Winston Documentation](https://github.com/winstonjs/winston)
- [Alertmanager Documentation](https://prometheus.io/docs/alerting/latest/alertmanager/)

---

## ğŸ’¡ ì¶”ê°€ ê¶Œì¥ì‚¬í•­

### 1. ë¡œê·¸ ì§‘ê³„ (í–¥í›„ ê³ ë ¤)
MVP ë‹¨ê³„ì—ì„œëŠ” Winston íŒŒì¼ ë¡œê¹…ìœ¼ë¡œ ì¶©ë¶„í•˜ì§€ë§Œ, ì„œë¹„ìŠ¤ í™•ì¥ ì‹œ ELK Stack ë˜ëŠ” Loki ë„ì…ì„ ê¶Œì¥í•©ë‹ˆë‹¤.

### 2. APM (Application Performance Monitoring)
í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” New Relic, Datadog ê°™ì€ APM ë„êµ¬ë¥¼ í†µí•´:
- ìë™ ì—ëŸ¬ ì¶”ì 
- íŠ¸ëœì­ì…˜ ì¶”ì 
- ì„±ëŠ¥ ë³‘ëª© ë¶„ì„

### 3. ë¹„ìš© ê³ ë ¤ì‚¬í•­
- Prometheus + Grafana: ì˜¤í”ˆì†ŒìŠ¤ (ë¬´ë£Œ)
- Grafana Cloud: ë¬´ë£Œ í‹°ì–´ ì œê³µ (50GB logs, 10k series)
- Self-hosted ë¹„ìš©: ì„œë²„ ë¦¬ì†ŒìŠ¤ë§Œ í•„ìš”

### 4. ë³´ì•ˆ
- Grafana ê¸°ë³¸ íŒ¨ìŠ¤ì›Œë“œ ë³€ê²½ í•„ìˆ˜
- Prometheus `/metrics` ì—”ë“œí¬ì¸íŠ¸ ì ‘ê·¼ ì œí•œ (IP í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸)
- Alertmanager Webhook URL í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©

---

**ì‘ì„±ì¼:** 2025-12-27
**ë²„ì „:** 1.0
**ì‘ì„±ì:** Claude (Anthropic)
